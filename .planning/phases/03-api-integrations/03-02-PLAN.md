---
phase: 03-api-integrations
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - lib/api/claude.ts
  - lib/pipeline/store.ts
autonomous: false
user_setup:
  - service: anthropic
    why: "Recipe structuring via Claude API"
    env_vars:
      - name: EXPO_PUBLIC_ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys -> Create Key"

must_haves:
  truths:
    - "Claude service structures transcript into recipe format"
    - "Pipeline uses real Whisper API for transcription"
    - "Pipeline uses real Claude API for structuring"
    - "Structured recipe contains title, ingredients array, and steps array"
    - "API errors surface to user with appropriate messages"
  artifacts:
    - path: "lib/api/claude.ts"
      provides: "Claude recipe structuring service"
      exports: ["structureRecipe"]
    - path: "lib/pipeline/store.ts"
      provides: "Pipeline with real API integration"
      contains: "transcribeAudio"
  key_links:
    - from: "lib/api/claude.ts"
      to: "@anthropic-ai/sdk"
      via: "Anthropic client"
      pattern: "new Anthropic"
    - from: "lib/api/claude.ts"
      to: "lib/api/errors.ts"
      via: "StructuringError import"
      pattern: "import.*StructuringError.*from.*errors"
    - from: "lib/pipeline/store.ts"
      to: "lib/api/whisper.ts"
      via: "transcribeAudio import"
      pattern: "import.*transcribeAudio.*from.*api/whisper"
    - from: "lib/pipeline/store.ts"
      to: "lib/api/claude.ts"
      via: "structureRecipe import"
      pattern: "import.*structureRecipe.*from.*api/claude"
---

<objective>
Create Claude recipe structuring service and integrate real APIs into the processing pipeline.

Purpose: Complete the API integration by adding Claude-powered recipe structuring and wiring both Whisper and Claude into the existing pipeline. This transforms the app from mock data to real AI-powered recipe extraction.

Output: Working end-to-end flow where real audio is transcribed by Whisper and structured by Claude into a recipe.
</objective>

<execution_context>
@/Users/damienanselmi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/damienanselmi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-api-integrations/03-RESEARCH.md
@.planning/phases/03-api-integrations/03-01-SUMMARY.md
@lib/api/errors.ts
@lib/api/config.ts
@lib/api/whisper.ts
@lib/pipeline/store.ts
@lib/pipeline/mock-api.ts
@lib/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Anthropic SDK and create Claude structuring service</name>
  <files>
    - package.json
    - lib/api/claude.ts
  </files>
  <action>
Install Anthropic SDK:
```bash
npm install @anthropic-ai/sdk --legacy-peer-deps
```

Create `lib/api/claude.ts` implementing recipe structuring with structured outputs:

```typescript
import Anthropic from '@anthropic-ai/sdk';
import { z } from 'zod';
import { zodToJsonSchema } from 'zod-to-json-schema';
import { StructuringError } from './errors';
import { NewRecipe } from '@/lib/types';
```

Define RecipeSchema using Zod:
```typescript
const RecipeSchema = z.object({
  title: z.string().describe('The name of the dish'),
  ingredients: z.array(z.string()).describe('List of ingredients with quantities'),
  steps: z.array(z.string()).describe('Numbered cooking steps in order'),
});
```

Create SYSTEM_PROMPT as shown in 03-RESEARCH.md.

Export `structureRecipe(transcript: string, apiKey: string): Promise<NewRecipe>`:
1. Create Anthropic client with provided apiKey
2. Call `client.messages.create()` with:
   - model: 'claude-sonnet-4-5-20250929'
   - max_tokens: 4096
   - system: SYSTEM_PROMPT
   - messages: user message with transcript
   - Use JSON schema approach for structured output (convert Zod schema via zodToJsonSchema)
3. Check response.stop_reason for 'refusal' or 'max_tokens'
4. Parse JSON from response.content[0].text
5. Return NewRecipe with title, ingredients, steps, sourceUrl: null, thumbnailUrl: null
6. Wrap errors in StructuringError

Note: Use `zodToJsonSchema` from zod-to-json-schema package instead of SDK helper if SDK helper not available. Install if needed: `npm install zod-to-json-schema --legacy-peer-deps`

For structured output, use the tools/tool_choice pattern if output_config not available:
```typescript
tools: [{
  name: 'extract_recipe',
  description: 'Extract structured recipe from transcript',
  input_schema: zodToJsonSchema(RecipeSchema)
}],
tool_choice: { type: 'tool', name: 'extract_recipe' }
```

Then parse from `response.content.find(c => c.type === 'tool_use')?.input`.
  </action>
  <verify>
- `npm run lint` passes
- `lib/api/claude.ts` exports `structureRecipe` function
- Function signature: `(transcript: string, apiKey: string) => Promise<NewRecipe>`
- Imports StructuringError from ./errors
- Imports NewRecipe from @/lib/types
  </verify>
  <done>
Claude structuring service ready. Function accepts transcript and API key, returns structured NewRecipe, handles errors with typed StructuringError.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate real APIs into pipeline store</name>
  <files>
    - lib/pipeline/store.ts
  </files>
  <action>
Modify `lib/pipeline/store.ts` to use real APIs for transcribing and structuring stages:

1. Add imports at top:
```typescript
import { transcribeAudio } from '@/lib/api/whisper';
import { structureRecipe } from '@/lib/api/claude';
import { getOpenAIKey, getAnthropicKey } from '@/lib/api/config';
```

2. Keep mock imports for download and extract (Phase 4 will replace these):
```typescript
import { mockDownload, mockExtract } from './mock-api';
```

3. In `startProcessing()`, update the transcribing stage:
```typescript
// Stage 3: Transcribing - NOW REAL
const openaiKey = await getOpenAIKey();
const transcript = await transcribeAudio(audioUri, openaiKey);
set({ stage: 'structuring', progress: 0.75 });
```

4. Update the structuring stage:
```typescript
// Stage 4: Structuring - NOW REAL
const anthropicKey = await getAnthropicKey();
const recipe = await structureRecipe(transcript, anthropicKey);
set({ stage: 'complete', progress: 1 });
```

5. Note: `audioUri` comes from mockExtract() which currently returns 'extracted_audio' string.
   For now, this will fail at runtime because we don't have real audio.
   That's expected - Phase 4 will provide real audio files.

   For testing, we can add a development mode flag or test with a real audio file URI.
   Add a TODO comment: `// TODO: Phase 4 will provide real audioUri from video extraction`

6. Update error handling to surface API error messages:
```typescript
} catch (error) {
  let message = 'Processing failed';
  if (error instanceof Error) {
    message = error.message;
  }
  set({ stage: 'error', error: message });
  return null;
}
```
  </action>
  <verify>
- `npm run lint` passes
- store.ts imports transcribeAudio, structureRecipe, getOpenAIKey, getAnthropicKey
- store.ts still imports mockDownload, mockExtract (not removed)
- No TypeScript errors
  </verify>
  <done>
Pipeline store wired to real APIs. Transcribing stage uses Whisper, structuring stage uses Claude. Download/extract remain mocked for Phase 4.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: Verify API integration works end-to-end</name>
  <what-built>
Real API integration for transcription (Whisper) and structuring (Claude). The pipeline now calls real AI services instead of returning mock data.
  </what-built>
  <how-to-verify>
**Pre-requisites:**
1. Create `.env` file with your API keys:
   ```
   EXPO_PUBLIC_OPENAI_API_KEY=sk-your-openai-key
   EXPO_PUBLIC_ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
   ```

2. For testing without Phase 4's video extraction, we need a test audio file.
   Option A: Temporarily modify mockExtract() to return a real audio file URI
   Option B: Wait for Phase 4 (current integration will error at transcription step)

**If testing with real audio (Option A):**
1. Place a test .m4a audio file in your device/simulator
2. Update mockExtract() temporarily to return the file URI
3. Run the app: `npx expo start`
4. Enter any URL and trigger processing
5. Verify:
   - Processing progresses through all stages
   - Final recipe has DIFFERENT content than the mock "Creamy Garlic Tuscan Shrimp"
   - Recipe reflects actual content from the audio file

**If deferring to Phase 4 (Option B):**
1. Run the app: `npx expo start`
2. Enter any URL and trigger processing
3. Verify:
   - Processing starts and reaches "transcribing" stage
   - Error appears (expected - no real audio file yet)
   - Error message is descriptive (from API, not generic)

**Code verification:**
1. Check `lib/api/claude.ts` - function exists and compiles
2. Check `lib/api/whisper.ts` - function exists and compiles
3. Check `lib/pipeline/store.ts` - imports real API functions
  </how-to-verify>
  <resume-signal>Type "approved" if integration is verified, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. All API files exist: lib/api/errors.ts, config.ts, whisper.ts, claude.ts
2. Pipeline store imports and uses real API functions
3. No TypeScript/lint errors: `npm run lint`
4. App builds: `npx expo export --platform ios`
5. Human verified API integration works (or errors appropriately without audio)
</verification>

<success_criteria>
- lib/api/claude.ts exports structureRecipe function
- lib/pipeline/store.ts uses real transcribeAudio and structureRecipe
- Mock download/extract preserved (for Phase 4 to replace)
- No lint errors, app builds
- Human verified the integration
</success_criteria>

<output>
After completion, create `.planning/phases/03-api-integrations/03-02-SUMMARY.md`
</output>
